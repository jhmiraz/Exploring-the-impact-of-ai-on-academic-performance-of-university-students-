# -*- coding: utf-8 -*-
"""advance_cleaning .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N72nHf04ChCCjnS34DYXvvUyDKYqKE-e
"""

import pandas as pd

# Load the Excel file
file_path = 'Modified_Data.xlsx'  # Replace with your file path
df = pd.read_excel(file_path)

# Display the first few rows of the dataset
print("Dataset Head:\n", df.head())

# Check for missing values
print("Missing Values Before Handling:\n", df.isnull().sum())

# Impute missing values with mode
for column in df.select_dtypes(include='object').columns:
    df[column].fillna(df[column].mode()[0], inplace=True)

# Alternatively, replace with 'Unknown'
# df.fillna('Unknown', inplace=True)

# Verify missing values are handled
print("Missing Values After Handling:\n", df.isnull().sum())

# Check for duplicates
print("Duplicate Rows Before Removal:", df.duplicated().sum())

# Remove duplicates
df = df.drop_duplicates()

# Verify duplicates are removed
print("Duplicate Rows After Removal:", df.duplicated().sum())

# Inspect unique values in each column
for column in df.select_dtypes(include='object').columns:
    print(f"Unique values in {column}:\n", df[column].value_counts())

# Optional: Merge rare categories (example for one column)
# df['column_name'] = df['column_name'].replace(['RareCategory'], 'ParentCategory')

# Define thresholds for rare categories
threshold = 10  # Categories with less than 10 occurrences will be merged

# Function to merge rare categories
def merge_rare_categories(column):
    value_counts = df[column].value_counts()
    rare_categories = value_counts[value_counts < threshold].index
    df[column] = df[column].replace(rare_categories, 'Other')

# Apply this function to relevant columns
categorical_columns = [
    "2.How familiar are you with the concept of Artificial Intelligence (AI) in education?",
    "3.How often do you use AI-powered educational tools or platforms for learning purposes?",
    "4. What is your perception of the impact of AI on the education sector?",
    # Add other relevant columns here
]

for column in categorical_columns:
    merge_rare_categories(column)

# Verify the updated unique values
for column in categorical_columns:
    print(f"Updated unique values in {column}:\n", df[column].value_counts())



import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load the raw data (assuming it's in an XLSX file)
df = pd.read_excel('label_encoded_survey_data.xlsx', sheet_name='Sheet1')

# Step 1: Handle Missing Values (if not already done)
for col in df.columns:
    if df[col].isnull().sum() > 0:
        most_frequent_value = df[col].mode()[0]
        df[col] = df[col].fillna(most_frequent_value)

# Step 2: Separate Features and Target
target_col = '9. Do you think AI has the potential to improve student retention rates over the long run?'
X = df.drop(columns=[target_col])
y = df[target_col]

# Step 3: Apply regular SMOTE since all features are numerical
smote = SMOTE(random_state=42)

# Fit and generate synthetic samples (new synthetic samples = 190)
X_balanced, y_balanced = smote.fit_resample(X, y)

# Step 4: Split the new synthetic data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)

# Check the new shape of X (should have increased size)
print(f"Original data shape: {X.shape}")
print(f"Synthetic data shape: {X_balanced.shape}")

# Optional: After generating synthetic samples, you can continue with encoding for model training
# For example, label encoding for the target variable (if not already done)
label_encoder = LabelEncoder()
y_balanced = label_encoder.fit_transform(y_balanced)

# Now you can use this data to train your model

# Create a DataFrame for the synthetic data
X_balanced_df = pd.DataFrame(X_balanced, columns=X.columns)
y_balanced_df = pd.Series(y_balanced, name=target_col)

# Combine the features and target into a single DataFrame
balanced_data = pd.concat([X_balanced_df, y_balanced_df], axis=1)

# Save the balanced data to a new Excel file
balanced_data.to_excel('balanced_synthetic_data.xlsx', index=False)

print("Synthetic data saved to 'balanced_synthetic_data.xlsx'")

# Save the label-encoded dataset
output_file = 'survey_data.xlsx'
df.to_excel(output_file, index=False)
print(f"survey data saved to {output_file}")